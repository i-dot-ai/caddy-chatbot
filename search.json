[
  {
    "objectID": "docs/about_caddy.html",
    "href": "docs/about_caddy.html",
    "title": "Quickstart",
    "section": "",
    "text": "Introducing Caddy\nCaddy is an AI-powered assistant acts as a copilot for customer service agents, empowering them to provide high-quality, actionable advice quickly and securely. When agents Caddy a question, Caddy will provide an answer based on all the content sources it’s been provided and give the agent references to the information.\nCaddy is designed to be used in settings where customer service advisers are supervised by experienced staff who can verify Caddy’s responses. Caddy’s responses are sent to a supervisor to review before they are made available to the customer-facing adviser. This “human in the loop” validation system is employed to mitigate risk, ensuring advice accuracy and reliability.\nEnvironments\nCaddy is built using AWS Serverless architecture and currently integrates with Google Workspace. We plan on building a Teams version later in the year.\n\n\n\nCaddy Workflow\n\n\nInstallation\nAdding users\nThere are two levels of user: supervisors and advisors.\nAdvisors can ask questions to Caddy, and will only see responses that have been approved by a supervisor (they will see a supervisor’s comments if the supervisor does not approve Caddy’s response).\nSupervisors have elevated privileges. They can: approve Caddy’s responses, add users (including other supervisors) and remove users.\nThe mechanism for adding both types of user is the same. To add a user, a user with supervisor permissions types ‘/addUser’ in the chat bar of a supervisor space.\n\n\n\nAdd users through slash commands in the chat\n\n\n\n\n\nInput the user’s email address\n\n\nRemoving users\nSupervisors can remove other users.\n \n\n\n\n\n\nclassDiagram\n    class Messages {\n        messageId\n        message\n        conversationId\n        userEmail\n        client\n        messageRecievedTimestamp\n        messageSentTimestamp\n    }\n    class Responses {\n        responseId\n        llmResponseJson\n        llmPrompt\n        messageId\n        llmAnswer\n        userThankedTimestamp\n        llmPromptTimestamp\n        llmResponseTimestamp\n        approverEmail\n        approved\n        approvalTimestamp\n        userResponseTimestamp\n    }\n    class Users {\n        userEmail\n        supervisionSpaceId\n        createdAt\n        isApprover\n        isSuperUser\n    }\n    Users -- Messages : UserId\n    Messages -- Responses : MessageId\n\n\n\n\n\n\nReviewing a Caddy response\n \nApprove the response\nReject the response",
    "crumbs": [
      "Docs",
      "Quickstart"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Caddy",
    "section": "",
    "text": "This is the homepage for Caddy and how wonderful it is."
  },
  {
    "objectID": "tests/notebooks/topic_evaluation.html",
    "href": "tests/notebooks/topic_evaluation.html",
    "title": "Topic modelling & Caddy performance evaluation",
    "section": "",
    "text": "A note book to evaluate the messages recieved previously, categorise into topics and judge approval rate of those messages\nLooking for an output that shows performance across various topics as well as demand to support with corpus scraping and maintenance\nSteps: 1) Locate data of historical messages / responses in download from s3 2) Use topic modelling to categorise the message / responses 3) Look at the approval rate of the messages\nImport all libraries\n\nimport boto3\nimport pandas as pd\nimport re\nfrom bertopic import BERTopic\nfrom sentence_transformers import SentenceTransformer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n/Users/max.hollingdale/Library/Caches/pypoetry/virtualenvs/caddy-chatbot-B-atQbAG-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nStep 1: Ingest data\n\nsession = boto3.Session()\ncredentials = session.get_credentials()\n\n# === Database Connections ===\ndynamodb = boto3.resource(\"dynamodb\", region_name=\"eu-west-2\")\n\n# === Tables ===\nresponses_table = dynamodb.Table(\"caddyResponses-prod\")\n\nresponses_data = responses_table.scan()['Items']\n\nStep 1a: Clean data\n\ndf_responses = pd.DataFrame(responses_data)\ndf_responses['Office'] = df_responses.apply(lambda x: str(x['approverEmail']).split('@')[-1], axis=1)\n\n\ndef clean_and_extract_urls(llm_response):\n\n    # Step 1: Remove the &lt;font&gt; tag and its attributes\n    cleaned_text = re.sub(r'&lt;font[^&gt;]*&gt;', '', llm_response)\n    cleaned_text = re.sub(r'&lt;/font&gt;', '', cleaned_text)\n\n    # Step 2: Extract and remove URLs\n    urls = re.findall(r'&lt;ref&gt;(.*?)&lt;/ref&gt;', cleaned_text)\n    cleaned_text = re.sub(r'&lt;ref&gt;(.*?)&lt;/ref&gt;', '', cleaned_text)\n\n    # Step 3: Further cleaning (remove remaining HTML tags, line breaks, etc.)\n    cleaned_text = re.sub(r'&lt;[^&gt;]+&gt;', '', cleaned_text)  # Remove any other HTML tags\n    cleaned_text = cleaned_text.replace('\\\\n', ' ').strip()  # Replace \\n with space and strip leading/trailing spaces\n\n    return cleaned_text, urls\n\ndf_responses[['cleaned_text', 'urls']] = df_responses['llmAnswer'].apply(lambda x: pd.Series(clean_and_extract_urls(x)))\n\n\n\nNow we have: - cleaned text which is the response from each llm - urls which is the rag documents returned - office which is the office of the individual messaging from - llmprompt which is the user query\nStep 2: Topic modelling\nUse bertopic as that is what consult ahve used and can ask them questions\nPros: Works well with short texts. No need to specify the number of topics in advance. Can use pre-trained language models for embeddings.\nCons: Requires more computational resources. More complex to set up compared to traditional methods.\nSeeding approach\n\n\nseed_topic_list = [\n    [\"finance\", \"debt\", \"support\", \"benefits\", \"universal\", \"charity\"],\n    [\"tax\", \"threshold\", \"guidance\", \"council\"],\n    [\"immigration\", \"visa\", \"asylum\", \"UK\"],\n    [\"housing\", \"rent\", \"landlord\"],\n    [\"health\", \"nhs\", \"care\"],\n    [\"violence\", \"abuse\", \"controlling\", \"family\",\"children\", \"partner\"],\n    # ... add more seed topics\n]\n\n# Initialize the sentence transformer model\nsentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Create embeddings\nembeddings = sentence_model.encode(df_responses['cleaned_text'].tolist(), show_progress_bar=True)\n\nmodel = BERTopic(language=\"english\", seed_topic_list=seed_topic_list)\ntopics, probabilities = model.fit_transform(df_responses['cleaned_text'], embeddings=embeddings)\n\n# Display topics\nprint(model.get_topic_info())\n\nBatches: 100%|██████████| 5/5 [00:00&lt;00:00,  8.59it/s]\n\n\n   Topic  Count                      Name  \\\n0     -1     37         -1_the_to_if_your   \n1      0     34  0_the_universal_your_for   \n2      1     33      1_the_to_landlord_if   \n3      2     18         2_the_pip_to_your   \n4      3     14          3_to_the_uk_your   \n5      4     14        4_the_to_client_if   \n\n                                      Representation  \\\n0  [the, to, if, your, you, for, client, and, or,...   \n1  [the, universal, your, for, to, you, credit, i...   \n2  [the, to, landlord, if, your, notice, client, ...   \n3  [the, pip, to, your, if, for, they, and, clien...   \n4  [to, the, uk, your, if, they, for, in, child, ...   \n5  [the, to, client, if, your, and, complaint, se...   \n\n                                 Representative_Docs  \n0  [TL;DR Your client may be able to get help fro...  \n1  [Brief Summary: Your client's Universal Credit...  \n2  [Brief Summary: To determine if the section 21...  \n3  [TL;DR: Your client may be able to get their E...  \n4  [Based on the information provided, it seems y...  \n5  [Based on the information provided, here is my...  \n\n\nScatterplot of embeddings, want to show spread\n\nfrom sklearn.decomposition import PCA\n\n# Reduce embeddings to 2D\npca = PCA(n_components=2)\ndoc_2d = pca.fit_transform(embeddings)\n\nplt.figure(figsize=(12, 8))\nscatter = plt.scatter(doc_2d[:, 0], doc_2d[:, 1], c=topics, cmap='tab20')\nplt.colorbar(scatter)\nplt.title('Document Clusters')\nplt.xlabel('PCA Component 1')\nplt.ylabel('PCA Component 2')\nplt.show()\n\n\n\n\n\n\n\n\nWord cloud\n\nfrom wordcloud import WordCloud\n\ndef plot_word_cloud(topic):\n    words = dict(model.get_topic(topic))\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(words)\n    \n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(f'Topic {topic}')\n    plt.show()\n\n# Plot word cloud for each topic\nfor topic in set(topics):\n    if topic != -1:  # -1 is often used for outliers\n        plot_word_cloud(topic)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustom_labels = {\n    '-1': \"Outliers\",\n    '0': \"Universal Credit\",\n    '1': \"Housing\",\n    '2': \"Disability & PIP\",\n    '3': \"Immigration\",\n    '4': \"Consumer goods and services\"\n}\n\n\n# Add the topics to the dataframe\ndf_responses['Topic'] = topics\n\n# Get the topic labels\ntopic_info = model.get_topic_info()\ntopic_labels = {row['Topic']: row['Name'] for _, row in topic_info.iterrows()}\n\n# Add the topic labels to the dataframe\ndf_responses['Topic_Label'] = df_responses['Topic'].map(topic_labels)\n\n\ndf_responses['Custom topics'] = df_responses['Topic'].map(custom_labels)\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\ndf_responses['Custom topics'].value_counts().plot(kind='bar')\nplt.title('Distribution of Topics')\nplt.xlabel('Topic')\nplt.ylabel('Count')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nStep 3: Look at approval rate of topics\n\ndf_responses.columns\n\nIndex(['approvalTimestamp', 'approverEmail', 'approverReceivedTimestamp',\n       'llmResponseTimestamp', 'userThankedTimestamp', 'approved',\n       'llmPromptTimestamp', 'messageId', 'llmAnswer', 'supervisorMessage',\n       'llmResponseJSon', 'responseId', 'llmPrompt', 'threadId',\n       'userResponseTimestamp', 'Office', 'cleaned_text', 'urls', 'Topic',\n       'Topic_Label', 'Custom topics'],\n      dtype='object')\n\n\n\ndf_responses_approved = df_responses[['approved','Office','Custom topics']].groupby(by='approved', axis=1)\n\n\ndf_responses_approved\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x39fe72360&gt;\n\n\n\n\n\n# Create a cross-tabulation of Topic_Label and another relevant column\n# For example, if you have an 'Office' column:\ncross_tab = pd.crosstab(df_responses['Custom topic'], df_responses['Office'])\n\n# If you don't have an 'Office' column, you can use any other relevant categorical column\n# Or, if you want to see co-occurrence of topics:\n# cross_tab = pd.crosstab(df_responses['Topic_Label'], df_responses['Topic_Label'])\n\n# Normalize the cross-tabulation\ncross_tab_normalized = cross_tab.div(cross_tab.sum(axis=1), axis=0)\n\n# Create a heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(cross_tab_normalized, annot=True, cmap='YlOrBr', fmt='.2f')\nplt.title('Topic Distribution Heatmap')\nplt.ylabel('Topic')\nplt.xlabel('Office')  # Change this if you're using a different column\nplt.tight_layout()\nplt.show()\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile ~/Library/Caches/pypoetry/virtualenvs/caddy-chatbot-B-atQbAG-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-&gt; 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'Custom topic'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\nCell In[95], line 3\n      1 # Create a cross-tabulation of Topic_Label and another relevant column\n      2 # For example, if you have an 'Office' column:\n----&gt; 3 cross_tab = pd.crosstab(df_responses['Custom topic'], df_responses['Office'])\n      5 # If you don't have an 'Office' column, you can use any other relevant categorical column\n      6 # Or, if you want to see co-occurrence of topics:\n      7 # cross_tab = pd.crosstab(df_responses['Topic_Label'], df_responses['Topic_Label'])\n      8 \n      9 # Normalize the cross-tabulation\n     10 cross_tab_normalized = cross_tab.div(cross_tab.sum(axis=1), axis=0)\n\nFile ~/Library/Caches/pypoetry/virtualenvs/caddy-chatbot-B-atQbAG-py3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102, in DataFrame.__getitem__(self, key)\n   4100 if self.columns.nlevels &gt; 1:\n   4101     return self._getitem_multilevel(key)\n-&gt; 4102 indexer = self.columns.get_loc(key)\n   4103 if is_integer(indexer):\n   4104     indexer = [indexer]\n\nFile ~/Library/Caches/pypoetry/virtualenvs/caddy-chatbot-B-atQbAG-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)\n   3807     if isinstance(casted_key, slice) or (\n   3808         isinstance(casted_key, abc.Iterable)\n   3809         and any(isinstance(x, slice) for x in casted_key)\n   3810     ):\n   3811         raise InvalidIndexError(key)\n-&gt; 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n   3817     self._check_indexing_error(key)\n\nKeyError: 'Custom topic'\n\n\n\n\nimport pandas as pd\n\n# Create a cross-tabulation of Office and Topic_Label\ncross_tab = pd.crosstab(df_responses['Office'], df_responses['Custom topics'])\n\n# Create a stacked bar chart\ncross_tab.plot(kind='bar', stacked=True, figsize=(12, 6))\nplt.title('Topic Distribution Across Offices')\nplt.xlabel('Office')\nplt.ylabel('Count')\nplt.legend(title='Topic', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n# Create a cross-tabulation of Office and Topic_Label\ncross_tab = pd.crosstab(df_responses['Custom topics'], df_responses['approved'])\n\n# Define colors for the bars based on exact column names\ncolor_map = {\n    True: 'green',  # Adjust these if your column names are not exactly `True`/`False`\n    False: 'orange'\n}\n\n# Create a list of colors corresponding to each column in cross_tab\ncolors = [color_map.get(col, 'gray') for col in cross_tab.columns]\n\n# Create a stacked bar chart\ncross_tab.plot(kind='bar', stacked=True, figsize=(12, 6), color=colors)\nplt.title('Approval Distribution Across Topics')\nplt.xlabel('Topic')\nplt.ylabel('Approval count')\nplt.legend(title='Approval', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()"
  }
]