{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling & Caddy performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note book to evaluate the messages recieved previously, categorise into topics and judge approval rate of those messages\n",
    "\n",
    "Looking for an output that shows performance across various topics as well as demand to support with corpus scraping and maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1) Locate data of historical messages / responses in download from s3\n",
    "2) Use topic modelling to categorise the message / responses\n",
    "3) Look at the approval rate of the messages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import re\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "\n",
    "# === Database Connections ===\n",
    "dynamodb = boto3.resource(\"dynamodb\", region_name=\"eu-west-2\")\n",
    "\n",
    "# === Tables ===\n",
    "responses_table = dynamodb.Table(\"caddyResponses-prod\")\n",
    "\n",
    "responses_data = responses_table.scan()[\"Items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1a: Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses = pd.DataFrame(responses_data)\n",
    "df_responses[\"Office\"] = df_responses.apply(\n",
    "    lambda x: str(x[\"approverEmail\"]).split(\"@\")[-1], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_extract_urls(llm_response):\n",
    "    # Step 1: Remove the <font> tag and its attributes\n",
    "    cleaned_text = re.sub(r\"<font[^>]*>\", \"\", llm_response)\n",
    "    cleaned_text = re.sub(r\"</font>\", \"\", cleaned_text)\n",
    "\n",
    "    # Step 2: Extract and remove URLs\n",
    "    urls = re.findall(r\"<ref>(.*?)</ref>\", cleaned_text)\n",
    "    cleaned_text = re.sub(r\"<ref>(.*?)</ref>\", \"\", cleaned_text)\n",
    "\n",
    "    # Step 3: Further cleaning (remove remaining HTML tags, line breaks, etc.)\n",
    "    cleaned_text = re.sub(r\"<[^>]+>\", \"\", cleaned_text)  # Remove any other HTML tags\n",
    "    cleaned_text = cleaned_text.replace(\n",
    "        \"\\\\n\", \" \"\n",
    "    ).strip()  # Replace \\n with space and strip leading/trailing spaces\n",
    "\n",
    "    return cleaned_text, urls\n",
    "\n",
    "\n",
    "df_responses[[\"cleaned_text\", \"urls\"]] = df_responses[\"llmAnswer\"].apply(\n",
    "    lambda x: pd.Series(clean_and_extract_urls(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have:\n",
    "- cleaned text which is the response from each llm\n",
    "- urls which is the rag documents returned\n",
    "- office which is the office of the individual messaging from\n",
    "- llmprompt which is the user query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bertopic as that is what consult ahve used and can ask them questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "Works well with short texts.\n",
    "No need to specify the number of topics in advance.\n",
    "Can use pre-trained language models for embeddings.\n",
    "\n",
    "Cons:\n",
    "Requires more computational resources.\n",
    "More complex to set up compared to traditional methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeding approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [\n",
    "    [\"finance\", \"debt\", \"support\", \"benefits\", \"universal\", \"charity\"],\n",
    "    [\"tax\", \"threshold\", \"guidance\", \"council\"],\n",
    "    [\"immigration\", \"visa\", \"asylum\", \"UK\"],\n",
    "    [\"housing\", \"rent\", \"landlord\"],\n",
    "    [\"health\", \"nhs\", \"care\"],\n",
    "    [\"violence\", \"abuse\", \"controlling\", \"family\", \"children\", \"partner\"],\n",
    "    # ... add more seed topics\n",
    "]\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = sentence_model.encode(\n",
    "    df_responses[\"cleaned_text\"].tolist(), show_progress_bar=True\n",
    ")\n",
    "\n",
    "model = BERTopic(language=\"english\", seed_topic_list=seed_topic_list)\n",
    "topics, probabilities = model.fit_transform(\n",
    "    df_responses[\"cleaned_text\"], embeddings=embeddings\n",
    ")\n",
    "\n",
    "# Display topics\n",
    "print(model.get_topic_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot of embeddings, want to show spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce embeddings to 2D\n",
    "pca = PCA(n_components=2)\n",
    "doc_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(doc_2d[:, 0], doc_2d[:, 1], c=topics, cmap=\"tab20\")\n",
    "plt.colorbar(scatter)\n",
    "plt.title(\"Document Clusters\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "def plot_word_cloud(topic):\n",
    "    words = dict(model.get_topic(topic))\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400, background_color=\"white\"\n",
    "    ).generate_from_frequencies(words)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Topic {topic}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot word cloud for each topic\n",
    "for topic in set(topics):\n",
    "    if topic != -1:  # -1 is often used for outliers\n",
    "        plot_word_cloud(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_labels = {\n",
    "    \"-1\": \"Outliers\",\n",
    "    \"0\": \"Universal Credit\",\n",
    "    \"1\": \"Housing\",\n",
    "    \"2\": \"Disability & PIP\",\n",
    "    \"3\": \"Immigration\",\n",
    "    \"4\": \"Consumer goods and services\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the topics to the dataframe\n",
    "df_responses[\"Topic\"] = topics\n",
    "\n",
    "# Get the topic labels\n",
    "topic_info = model.get_topic_info()\n",
    "topic_labels = {row[\"Topic\"]: row[\"Name\"] for _, row in topic_info.iterrows()}\n",
    "\n",
    "# Add the topic labels to the dataframe\n",
    "df_responses[\"Topic_Label\"] = df_responses[\"Topic\"].map(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses[\"Custom topics\"] = df_responses[\"Topic\"].map(custom_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_responses[\"Custom topics\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of Topics\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Look at approval rate of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses_approved = df_responses[[\"approved\", \"Office\", \"Custom topics\"]].groupby(\n",
    "    by=\"approved\", axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses_approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of Topic_Label and another relevant column\n",
    "# For example, if you have an 'Office' column:\n",
    "cross_tab = pd.crosstab(df_responses[\"Custom topic\"], df_responses[\"Office\"])\n",
    "\n",
    "# If you don't have an 'Office' column, you can use any other relevant categorical column\n",
    "# Or, if you want to see co-occurrence of topics:\n",
    "# cross_tab = pd.crosstab(df_responses['Topic_Label'], df_responses['Topic_Label'])\n",
    "\n",
    "# Normalize the cross-tabulation\n",
    "cross_tab_normalized = cross_tab.div(cross_tab.sum(axis=1), axis=0)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cross_tab_normalized, annot=True, cmap=\"YlOrBr\", fmt=\".2f\")\n",
    "plt.title(\"Topic Distribution Heatmap\")\n",
    "plt.ylabel(\"Topic\")\n",
    "plt.xlabel(\"Office\")  # Change this if you're using a different column\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a cross-tabulation of Office and Topic_Label\n",
    "cross_tab = pd.crosstab(df_responses[\"Office\"], df_responses[\"Custom topics\"])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "cross_tab.plot(kind=\"bar\", stacked=True, figsize=(12, 6))\n",
    "plt.title(\"Topic Distribution Across Offices\")\n",
    "plt.xlabel(\"Office\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Topic\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a cross-tabulation of Office and Topic_Label\n",
    "cross_tab = pd.crosstab(df_responses[\"Custom topics\"], df_responses[\"approved\"])\n",
    "\n",
    "# Define colors for the bars based on exact column names\n",
    "color_map = {\n",
    "    True: \"green\",  # Adjust these if your column names are not exactly `True`/`False`\n",
    "    False: \"orange\",\n",
    "}\n",
    "\n",
    "# Create a list of colors corresponding to each column in cross_tab\n",
    "colors = [color_map.get(col, \"gray\") for col in cross_tab.columns]\n",
    "\n",
    "# Create a stacked bar chart\n",
    "cross_tab.plot(kind=\"bar\", stacked=True, figsize=(12, 6), color=colors)\n",
    "plt.title(\"Approval Distribution Across Topics\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Approval count\")\n",
    "plt.legend(title=\"Approval\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caddy-chatbot-B-atQbAG-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
