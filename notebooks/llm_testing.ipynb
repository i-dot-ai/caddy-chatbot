{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04757ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current directory\n",
    "import sys\n",
    "import os \n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from datetime import datetime\n",
    "from conversations.prompt import STANDALONE_PROMPT\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "llm = ChatAnthropic(anthropic_api_key=ANTHROPIC_API_KEY)\n",
    "retriever = AmazonKendraRetriever(index_id=\"2e02c2d0-5223-43f5-bd51-5423bb74aa1f\", region_name=\"eu-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ef16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUFFIX = \"\"\"\n",
    "Adviser: Here are a few documents in <documents> tags:\n",
    "<documents>\n",
    "{context}\n",
    "</documents>\n",
    "Based on the above documents, provide a detailed answer for, {question}. Be concise in your response and make sure to include reference to any location names \\\n",
    "stated in the question, and make sure your answer is relevant to the laws and rules of the location specified in the question. Also make sure to add a \"Sources:\" section \\\n",
    "at the end of your answer. The \"Sources:\" section should cite the url of the source documents you used in your answer. \\\n",
    "ONLY PUT CITED DOCUMENTS IN THE \"Sources:\" SECTION AND NO WHERE ELSE IN YOUR RESPONSE. IT IS CRUCIAL that citations only happens in the \"Sources:\" section. \\\n",
    "DO NOT INCLUDE ANY DOCUMENTS IN THE \"Sources:\" THAT YOU DID NOT USE IN YOUR RESPONSE.\n",
    "Example: \"Sources: <a href\"https://www.citizensadvice.org.uk/debt-and-money/help-with-debt/\">https://www.citizensadvice.org.uk/debt-and-money/help-with-debt/</a>\"\n",
    "\n",
    "If the question discusses 'my client', your answer should refer to 'your client'.\n",
    "\n",
    "If information is needed to definitively answer the question, phrase this as a step by step list of questions that the adviser should ask the client and use language like 'could be' instead if 'is'. In the list of questions, use simple language.\n",
    "\n",
    "\".\n",
    "\n",
    "Use <b>bold</b> to highlight the most question relevant parts in your response.\n",
    "\n",
    "Caddy:\n",
    "\"\"\"\n",
    "\n",
    "CORE_PROMPT = PromptTemplate.from_template(SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f368ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationEntityMemory(llm=llm)\n",
    "history = []\n",
    "prompt = \"How do I claim UC?\"\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    # condense_question_prompt={\"prompt\": STANDALONE_PROMPT},\n",
    "    # condense_question_prompt=STANDALONE_PROMPT,\n",
    "    # return_source_documents=True,\n",
    "    # return_generated_question=True,\n",
    "    # combine_docs_chain_kwargs={\"prompt\": CORE_PROMPT},\n",
    "    # combine_docs_chain_kwargs=CORE_PROMPT,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46986670",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain({'foo': 1, 'bar': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How do I claim UC?\"\n",
    "history = []\n",
    "# ai_response = chain({\"question\": prompt})\n",
    "# ai_response = chain({\"question\": prompt, \"chat_history\": history})\n",
    "chain.invoke({\"question\": prompt, \"chat_history\": history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15103eaffe05e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"prompt\": \"How does one eat a chicken\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020a0fb94fb6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7e327d62862b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(\n",
    "    input=\"\"\"\n",
    "    John helped Max study for a math exam. \n",
    "    Thanks to him, Max got a high grade from the exam.\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
